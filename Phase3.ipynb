{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IAU - Inteligentná analýza údajov (2024/2025)\n",
    "\n",
    "#### Autori: Jan Lenhart (50 %), Marek Čederle (50 %)\n",
    "##### Cvičenie: Pondelok 15:00, Cvičiaci: Ing. Oleksandr Lytvyn\n",
    "\n",
    "<font color='salmon'>\n",
    "    <b>Upozornenie:</b>\n",
    "    Niektoré bloky kódu trvajú dlhú dobu ak ide o trénovanie modelov a podobne. (runtime celeho dokumentu ~30 min)\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fáza 3 - Strojové učenie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from statistics import LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier, IsolationForest\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, classification_report\n",
    "from sklearn.tree import plot_tree, DecisionTreeClassifier\n",
    "from sklearn.feature_selection import SelectKBest, f_regression, f_classif, chi2, RFE, VarianceThreshold, SelectFromModel, mutual_info_regression\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, PowerTransformer, StandardScaler, RobustScaler, QuantileTransformer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, ClassifierMixin\n",
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na začiatok sme si importovali predspracované dáta z druhej fázy, s ktorými sme ďalej pracovali."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('preprocessed_train.csv', delimiter=',')\n",
    "test  = pd.read_csv('preprocessed_test.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train.drop(columns=['mwra']), test.drop(columns=['mwra']), train['mwra'], test['mwra']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([X_train, X_test])\n",
    "y = pd.concat([y_train, y_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Jednoduchý klasifikátor na základe závislosti v dátach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.A Naimplementujte jednoduchý ID3 klasifikátor s hĺbkou min 2 (vrátane root/koreň)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```py\n",
    "class CustomClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X, y = check_X_y(X, y)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        check_is_fitted(self)\n",
    "        X = check_array(X)\n",
    "        return np.zeros(X.shape[0])\n",
    "\n",
    "    def score(self, X, y):\n",
    "        y_pred = self.predict(X)\n",
    "        return np.mean(y_pred == y)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nasledujúci kód, predstavujúci vlastný ID3 klasifikátor sme implementovali z vyššie uvedeného kódu, ktorý bol generovaný pomocou ChatGPT. Daný kód predstavuje šablónu pre implementáciu vlastného klasifikátora knižnice `sklearn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# following code is co-engineered with ChatGPT\n",
    "class ID3Classifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self):\n",
    "        self.tree_ = None\n",
    "\n",
    "    def _entropy(self, y):\n",
    "        counts = np.bincount(y)\n",
    "        probabilities = counts / len(y)\n",
    "        return -np.sum([p * np.log2(p) for p in probabilities if p > 0])\n",
    "\n",
    "    def _information_gain(self, X, y, feature):\n",
    "        total_entropy = self._entropy(y)\n",
    "        values, counts = np.unique(X[:, feature], return_counts=True)\n",
    "        weighted_entropy = sum(\n",
    "            (counts[i] / sum(counts)) * self._entropy(y[X[:, feature] == values[i]])\n",
    "            for i in range(len(values))\n",
    "        )\n",
    "        return total_entropy - weighted_entropy\n",
    "    \n",
    "    def _get_optimal_threshold(self, X, y, feature):\n",
    "        values = np.unique(X[:, feature])\n",
    "        best_threshold = None\n",
    "        best_info_gain = -float('inf')\n",
    "        for value in values:\n",
    "            left_mask = X[:, feature] < value\n",
    "            right_mask = ~left_mask\n",
    "            left_y = y[left_mask]\n",
    "            right_y = y[right_mask]\n",
    "            \n",
    "            left_entropy = self._entropy(left_y)\n",
    "            right_entropy = self._entropy(right_y)\n",
    "            \n",
    "            weighted_entropy = (len(left_y) / len(y)) * left_entropy + (len(right_y) / len(y)) * right_entropy\n",
    "            info_gain = self._entropy(y) - weighted_entropy\n",
    "            \n",
    "            if info_gain > best_info_gain:\n",
    "                best_info_gain = info_gain\n",
    "                best_threshold = value\n",
    "\n",
    "        return best_threshold\n",
    "\n",
    "    def _id3(self, X, y, features):\n",
    "        if len(np.unique(y)) == 1:\n",
    "            return {'value': np.unique(y)[0]}\n",
    "        if len(features) == 0:\n",
    "            return {'value': np.bincount(y).argmax()}\n",
    "        best_feature = max(features, key=lambda f: self._information_gain(X, y, f))\n",
    "        best_threshold = self._get_optimal_threshold(X, y, best_feature)\n",
    "        tree = {'feature': best_feature, 'threshold': best_threshold, 'left': None, 'right': None}\n",
    "        left_mask = X[:, best_feature] < best_threshold\n",
    "        right_mask = ~left_mask\n",
    "        left_X, left_y = X[left_mask], y[left_mask]\n",
    "        right_X, right_y = X[right_mask], y[right_mask]\n",
    "        tree['left'] = self._id3(left_X, left_y, [f for f in features if f != best_feature])\n",
    "        tree['right'] = self._id3(right_X, right_y, [f for f in features if f != best_feature])\n",
    "        return tree\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        y = y.astype(int)\n",
    "        X, y = check_X_y(X, y)\n",
    "        self.tree_ = self._id3(X, y, range(X.shape[1]))\n",
    "        return self\n",
    "    \n",
    "    def _predict_instance(self, instance, tree):\n",
    "        if 'value' in tree:\n",
    "            return tree['value']\n",
    "        feature_value = instance[tree['feature']]\n",
    "        if feature_value <= tree['threshold']:\n",
    "            return self._predict_instance(instance, tree['left'])\n",
    "        return self._predict_instance(instance, tree['right'])\n",
    "\n",
    "    def predict(self, X):\n",
    "        check_is_fitted(self, \"tree_\")\n",
    "        X = check_array(X)\n",
    "        return np.array([self._predict_instance(row, self.tree_) for row in X])\n",
    "\n",
    "    # def score(self, X, y):\n",
    "    #     y_pred = self.predict(X)\n",
    "    #     return np.mean(y_pred == y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Opis funkcií vlastného ID3 klasifikátora:\n",
    "\n",
    "- `_entropy()`: Vypočíta entropiu podľa štandardného vzorca.\n",
    "\n",
    "- `_information_gain()`: Vypočíta information gain podľa štandardného vzorca.\n",
    "\n",
    "- `_get_optimal_threshold()`: Vypočíta optimálny threshold pre daný atribút (feature) na základe entropie a information gain.\n",
    "\n",
    "- `_id3()`: Zo vstupných dát vytvorí ID3 rozhodovací strom, ktorý sa trénuje.\n",
    "\n",
    "- `fit()`: Spústí trénovanie modelu.\n",
    "\n",
    "- `_predict_instance()`: Predikuje výsledok jednej inštancie resp. jedného riadoku dát.\n",
    "\n",
    "- `predict()`: Predikuje výsledné hodnoty na základe natrénovaného modelu a vstupených dát.\n",
    "\n",
    "<!-- - `score()`: Vypočíta skóre resp. presnosť (accuracy) modelu. -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avg runtime ~1 min\n",
    "id3_classifier = ID3Classifier()\n",
    "id3_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Jednoduchá CLI Style vizualizácia nášho ID3 rozhodovacieho stromu**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def id3_print_recursive(tree, X, y, depth = 0, left = False, right = False):\n",
    "    for i in range(depth):\n",
    "        print(end='  ')\n",
    "    if (left):\n",
    "        print('l-', end='')\n",
    "    if (right):\n",
    "        print('r-', end='')\n",
    "    if ('feature' in tree):\n",
    "        print(f\"feature: {X.columns[tree['feature']]}, threshold: {tree['threshold']}\")\n",
    "        if (tree['left']):\n",
    "            id3_print_recursive(tree['left'], X, y, depth + 1, left=True)\n",
    "        if (tree['right']):\n",
    "            id3_print_recursive(tree['right'], X, y, depth + 1, right=True)\n",
    "    else:\n",
    "        print(f\"value: {tree['value']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(id3_classifier.tree_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id3_print_recursive(id3_classifier.tree_, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.B Vyhodnoťte Váš ID3 klasifikátor pomocou metrík accuracy, precision a recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_eval(y, y_pred):\n",
    "    accuracy = accuracy_score(y, y_pred)\n",
    "    precision = precision_score(y, y_pred, average='weighted')\n",
    "    recall = recall_score(y, y_pred, average='weighted')\n",
    "\n",
    "    print(f\"Accuracy: {accuracy:.2f}\")\n",
    "    print(f\"Precision: {precision:.2f}\")\n",
    "    print(f\"Recall: {recall:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test data\n",
    "id3_y_pred_test = id3_classifier.predict(X_test)\n",
    "print_eval(y_test, id3_y_pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Môžeme vidieť že všetky naše metriky dávajú rovnakú hodnotu. Zároveň môžeme konštatovať, že úspešnosť `82%` nášho klasifikátora nie je zlá, ale ani nie je ideálna resp. nejde o najlepší machine learning model na základe naších dát."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.C Zístite či Váš ID3 klasifikátor má overfit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "id3_y_pred_train = id3_classifier.predict(X_train)\n",
    "id3_y_pred_train = pd.DataFrame(id3_y_pred_train, columns=['mwra'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train data\n",
    "print_eval(y_train, id3_y_pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test data\n",
    "print_eval(y_test, id3_y_pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rozdiel (delta) medzi trénovacou a testovacou množinou je `3%`, čo znamená, že náš model nemá overfit a celková úspešnosť je relatívne vysoká, čo značí že náš model nemá ani underfit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Trénovanie a vyhodnotenie klasifikátorov strojového učenia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.A Na trénovanie využite jeden stromový algoritmus v scikit-learn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ako stromový algoritmus sme si zvolili `RandomForestClassifier`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestClassifier(random_state=42, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train data\n",
    "rf_y_pred = rf_model.predict(X_train)\n",
    "\n",
    "print_eval(y_train, rf_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test data\n",
    "rf_y_pred = rf_model.predict(X_test)\n",
    "\n",
    "print_eval(y_test, rf_y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.B Porovnajte s jedným iným nestromovým algoritmom v scikit-learn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ako nestromový algoritmus sme si zvolili `SVC` (Support Vector Classifier)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_model = SVC(kernel='rbf', random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train data\n",
    "svc_y_pred = svc_model.predict(X_train)\n",
    "\n",
    "print_eval(y_train, svc_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test data\n",
    "svc_y_pred = svc_model.predict(X_test)\n",
    "\n",
    "print_eval(y_test, svc_y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.C Porovnajte výsledky s ID3 z prvého kroku."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre ukážku sme si vyskúšali ešte aj `DecisionTreeClassifier` klasifikátor, aby sme mali viacej modelov na porovnanie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "dt_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train data\n",
    "print_eval(y_train, dt_model.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test data\n",
    "dt_y_pred = dt_model.predict(X_test)\n",
    "print_eval(y_test, dt_y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Úspešnosť ID3 klasifikátora na testovacej množine je v porovnaní o `2%` menšia ako úspešnosť `RandomForestClassifier` a `SVC` klasifikátora. Na druhej strane je o `14%` lepšia ako `DecisionTreeClassifier`.\n",
    "\n",
    "Zároveň si môžeme všimnúť, že `ID3` a `SVC` modely nemajú ani underfit ani overfit, zatiaľ čo `RandomForestClassifier` a `DecisionTreeClassifier` majú overfit čo znamená, že nedokážu generalizovať na testovacej množine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.D Vizualizujte natrénované pravidlá minimálne pre jeden Vami vybraný algoritmus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rozhodli sme sa vizualiovať pravidlá pre `RandomForestClassifier` klasifikátor, pretože ide o veľký model, ktorý má viacej stromov, tak sme vizualizovali jeden čo je na nultom indexe (prvý strom v poradí)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avg runtime ~35 sec\n",
    "plt.figure(figsize=(12, 8))\n",
    "plot_tree(rf_model.estimators_[0], feature_names=X.columns, class_names=X.columns, filled=True)\n",
    "plt.title(\"Vizualizácia stromu na indexe č.0 RandomForest modelu\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Následne sme si urobili aj krajšiu vizualizáciu nášho `ID3` klasifikátora, ktorý je jednoduchší ako `RandomForest` a má len niekoľko pravidiel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def id3_plot_tree(tree, x=0.5, y=1, width=0.2, ax=None, feature_names=None, depth=0):\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    ax.axis('off')\n",
    "\n",
    "    if 'value' in tree:\n",
    "        ax.text(x, y, f'mwra: {tree[\"value\"]}', ha='center', va='center', \n",
    "                bbox=dict(facecolor='lightgray', edgecolor='black', boxstyle='round,pad=1'))\n",
    "        return ax\n",
    "\n",
    "    feature_name = feature_names[tree['feature']]\n",
    "    text = f'{feature_name} <= {tree[\"threshold\"]:.2f}' if tree['threshold'] else feature_name\n",
    "\n",
    "    ax.text(x, y, text, ha='center', va='center', bbox=dict(facecolor='lightblue', edgecolor='black', boxstyle='round,pad=1'))\n",
    "\n",
    "    left_x = x - width / 2\n",
    "    right_x = x + width / 2\n",
    "    child_y = y - 1 / (depth + 1)\n",
    "\n",
    "    if (tree['left']):\n",
    "        ax.plot([x, left_x], [y, child_y], 'k-')\n",
    "        id3_plot_tree(tree['left'], x=left_x, y=child_y, width=width / 2, ax=ax, feature_names=feature_names, depth=depth + 1)\n",
    "    if (tree['right']):\n",
    "        ax.plot([x, right_x], [y, child_y], 'k-')\n",
    "        id3_plot_tree(tree['right'], x=right_x, y=child_y, width=width / 2, ax=ax, feature_names=feature_names, depth=depth + 1)\n",
    "\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(40, 8))\n",
    "id3_plot_tree(id3_classifier.tree_, feature_names=X.columns, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.E Vyhodnoťte natrénované modely pomocou metrík accuracy, precision a recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vyhodnotenie metrík pre všetky modeli bolo spomenuté už vyššie v sekcii `3.2.C`, keď sme porovnávali ich úspešnosť a prítomnosť overfitu resp. underfitu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Optimalizácia alias hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.A Vyskúšajte rôzne nastavenie hyperparametrov (tuning) pre zvolený algoritmus tak, aby ste optimalizovali výkonnosť (bez underfitingu)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keďže `RandomForestClassifier` model mal overfit, tak sme si ho vybrali ako kandidáta na optimalizáciu pomocou hyperparameter tuningu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avg runtime\n",
    "# n_jobs=-1 ->  ~4 min\n",
    "\n",
    "model_new = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "\n",
    "param_grid_new = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [5, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 5]\n",
    "}\n",
    "\n",
    "grid_search_new = GridSearchCV(model_new, param_grid_new, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid_search_new.fit(X_train, y_train)\n",
    "\n",
    "tuning_model_new = grid_search_new.best_estimator_\n",
    "\n",
    "print(\"Best Parameters:\", grid_search_new.best_params_)\n",
    "print(\"Best Score:\", grid_search_new.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Tuning Model (RandomForest) Train Score:\", tuning_model_new.score(X_train, y_train))\n",
    "print(\"Tuning Model (RandomForest) Test  Score:\", tuning_model_new.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Môžeme si všimnúť, že model po optimalizácii nemá overfit, pretože delta medzi úspešnosťou trénovacej a testovacej množiny je `3%`, čo je výrazné zlepšenie oproti pôvodným `11%`. A ani underfit pretože úspešnosť je relatívne vysoká."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zároveň sme si vyskúšali hyperparameter tuning aj pre `SVC` model, ktorý nemal overfit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avg runtime ~\n",
    "# n_jobs=-1 -> 3 min\n",
    "\n",
    "model = SVC()\n",
    "\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'kernel': ['linear', 'rbf'],\n",
    "    'gamma': [0.01, 0.1, 1, 10]\n",
    "    # 'C': [10, 100, 1000],\n",
    "    # 'kernel': ['linear', 'rbf', 'poly'],\n",
    "    # 'gamma': [0.1, 0.01, 0.001]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "tuning_model = grid_search.best_estimator_\n",
    "\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Score:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Tuning Model (SVC) Train Score:\", tuning_model.score(X_train, y_train))\n",
    "print(\"Tuning Model (SVC) Test  Score:\", tuning_model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Môžeme vidieť, že jeho úspešnosť sa nijako nezmenila s tým, že model nemá underfit ani overfit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.B Vyskúšajte kombinácie modelov (ensemble) pre zvolený algoritmus tak, aby ste optimalizovali výkonnosť (bez underfitingu)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ako modely do ensemble sme si zvolili `RandomForestClassifier` a `SVC`, ktoré sme následne skombinovali do jedného modelu pomocou `StackingClassifier`. Ako parametre modelov sme určili tie, ktoré sme získali z hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avg runtime\n",
    "# n_jobs=-1 -> 40 sec\n",
    "\n",
    "base_models = [\n",
    "    ('svm', SVC(C=10, gamma=0.1, kernel='rbf', probability=True)),\n",
    "    ('tree', RandomForestClassifier(max_depth=10, min_samples_leaf=5, min_samples_split=2, n_estimators=200, n_jobs=-1))\n",
    "]\n",
    "\n",
    "stacking_model = StackingClassifier(estimators=base_models, final_estimator=LogisticRegression(), n_jobs=-1)\n",
    "stacking_model.fit(X_train, y_train)\n",
    "\n",
    "ensemble_model = stacking_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Enseble Model Train Score:\", ensemble_model.score(X_train, y_train))\n",
    "print(\"Enseble Model Test  Score:\", ensemble_model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Môžeme vidieť že úspešnosť modelu je `84%` na testovacej množine, čo značí o tom, že model nemá underfit. Bohužiaľ sa nám stále nedarí optimalizovať model tak, aby mal vyššiu úspešnosť."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.C Využite krížovú validáciu (cross validation) na trénovacej množine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Najskôr sme si urobili krížovú validáciu pre `RandomForestClassifier` model, ktorý sme optimalizovali pomocou parametrov ktoré nám vrátily `GridSearchCV` vyššie v dokumente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avg runtime ~50 sec\n",
    "# n_jobs=-1 -> 6 sec\n",
    "\n",
    "model = RandomForestClassifier(max_depth=10, min_samples_leaf=5, min_samples_split=2, n_estimators=200, n_jobs=-1)\n",
    "\n",
    "cv_scores = cross_val_score(model, X_train, y_train, cv=10, scoring='accuracy', n_jobs=-1)\n",
    "print(\"Cross-Validation Scores:\", cv_scores)\n",
    "print(\"Mean CV Score:\", cv_scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Následne sme si urobili krížovú validáciu pre `SVC` model, ktorý sme tiež pomocou `GridSearchCV` optimalizovali."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avg runtime ~25 sec\n",
    "# n_jobs=-1 -> 4 sec\n",
    "cv_scores = cross_val_score(tuning_model, X_train, y_train, cv=10, scoring='accuracy', n_jobs=-1)\n",
    "print(\"Cross-Validation Scores:\", cv_scores)\n",
    "print(\"Mean CV Score:\", cv_scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ako poslednú sme si vyskúšali krížovú validáciu pre `StackingClassifier` model, ktorý sme vytvorili z kombinácie `RandomForestClassifier` a `SVC` modelov."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avg runtime ~7,5 min\n",
    "# n_jobs=-1 -> 1,5 min\n",
    "cv_scores = cross_val_score(ensemble_model, X_train, y_train, cv=10, scoring='accuracy', n_jobs=-1)\n",
    "print(\"Cross-Validation Scores:\", cv_scores)\n",
    "print(\"Mean CV Score:\", cv_scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Môžeme si všimnúť že všetky 3 druhy krížovej validácie majú rovnakú úspešnosť."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.D Dokážte že Váš nastavený najlepší model je bez overfitingu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podľa predchádzajúcich metrík sme zistili, že náš doposial najlepší model je optimalizovaný `SVC` model pomocou hyperparameter tuningu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Tuning Model Train Score:\", tuning_model.score(X_train, y_train))\n",
    "print(\"Tuning Model Test  Score:\", tuning_model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podľa metriky `score` (`accuracy`) môžeme vidieť, že model nemá overfit, pretože delta medzi trénovacou a testovacou množinou je `~1%` a zároveň ani underfit pretože má relatívne vysokú úspešnosť."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Vyhodnotenie vplyvu zvolenej stratégie riešenia na klasifikáciu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aby sme vyhodnotili, či náš proces predspracovania a modelovania bol správny, urobili sme bruteforce medzi veľa kombináciami objektov z predprocesing pipeline.\n",
    "\n",
    "Urobili sme viacej iterácií bruteforce, kde po každej iterácii sme ju zanalyzovali a podľa nej sme navrhli ako má vyzerať ďalšia iterácia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na začiatku sme si načítali \"raw\" data a urobili sme si prípavu na robenie s pipelinami."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_connections = pd.read_csv('112/connections.csv', delimiter=',')\n",
    "df_processes   = pd.read_csv('112/processes.csv', delimiter=',')\n",
    "\n",
    "merged_data = df_connections.merge(df_processes, on=['imei', 'ts'], how='inner')\n",
    "merged_data['ts'] = pd.to_numeric(pd.to_datetime(merged_data['ts'], errors='coerce'))\n",
    "merged_data = merged_data.drop_duplicates()\n",
    "merged_data = merged_data.drop(columns=['mwra_y'])\n",
    "merged_data = merged_data.rename(columns={\"mwra_x\": \"mwra\"})\n",
    "\n",
    "X_raw = merged_data.drop(columns='mwra')\n",
    "y_raw = merged_data['mwra']\n",
    "\n",
    "X_raw_train, X_raw_test, y_raw_train, y_raw_test = train_test_split(X_raw, y_raw, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# co-engineered with ChatGPT - from phase 2\n",
    "class OutlierHandler(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, threshold=1.5, outlier_fraction=0.05):\n",
    "        self.threshold = threshold\n",
    "        self.outlier_fraction = outlier_fraction\n",
    "        self.imputer = SimpleImputer(strategy='median')\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.iqr = np.percentile(X, 75, axis=0) - np.percentile(X, 25, axis=0)\n",
    "        self.lower_bound = np.percentile(X, 25, axis=0) - self.threshold * self.iqr\n",
    "        self.upper_bound = np.percentile(X, 75, axis=0) + self.threshold * self.iqr\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        outliers_mask = np.any((X < self.lower_bound) | (X > self.upper_bound), axis=1)\n",
    "        num_outliers = np.sum(outliers_mask)\n",
    "        total_samples = X.shape[0]\n",
    "        outlier_fraction = num_outliers / total_samples\n",
    "        \n",
    "        if outlier_fraction < self.outlier_fraction:\n",
    "            return X[~outliers_mask]\n",
    "        else:\n",
    "            X_imputed = X.copy()\n",
    "            X_imputed[outliers_mask] = np.nan\n",
    "            return self.imputer.fit_transform(X_imputed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Takto vyzeral náš pipeline na konci 2 fázy:\n",
    "```py\n",
    "preprocessor_pipeline = \n",
    "Pipeline(\n",
    "    steps=[\n",
    "        ('imputer', SimpleImputer(strategy='mean')),\n",
    "        ('outlier_handler', OutlierHandler(threshold=1.5, outlier_fraction=0.05)),\n",
    "        ('scaler', MinMaxScaler()),\n",
    "        ('power_transformer', PowerTransformer(method='yeo-johnson')),\n",
    "        ('feature_selection', SelectKBest(mutual_info_regression, k=5))],\n",
    "    verbose=True\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Typy objektov, ktorých kombinácie sme skúšali v našom bruteforce:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we commented out the ones with worst scores so the broteforce doesnt run so long\n",
    "\n",
    "imputers = [\n",
    "    SimpleImputer(strategy='mean'),\n",
    "    SimpleImputer(strategy='median'),\n",
    "    # KNNImputer(n_neighbors=5)\n",
    "]\n",
    "\n",
    "outlier_handlers = [\n",
    "    OutlierHandler(threshold=1.5, outlier_fraction=0.05),\n",
    "    OutlierHandler(threshold=2.0, outlier_fraction=0.1)\n",
    "]\n",
    "\n",
    "scalers = [\n",
    "    MinMaxScaler(),\n",
    "    # StandardScaler(),\n",
    "    RobustScaler()\n",
    "]\n",
    "\n",
    "transformers = [\n",
    "    PowerTransformer(method='yeo-johnson'),\n",
    "    QuantileTransformer(output_distribution='normal'),\n",
    "    # QuantileTransformer(output_distribution='uniform')\n",
    "]\n",
    "\n",
    "feature_selections = [\n",
    "    SelectKBest(mutual_info_regression, k=5),\n",
    "    SelectKBest(f_regression, k=5),\n",
    "    # SelectKBest(f_classif, k=5),\n",
    "    # SelectKBest(chi2, k=5),\n",
    "    VarianceThreshold(threshold=0.1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [\n",
    "    svc_model,\n",
    "    tuning_model,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avg runtime ~9,5 min\n",
    "# 45 min last run\n",
    "evaluated_models = []\n",
    "good_preprocessor_count = 0\n",
    "good_classifier_count = 0\n",
    "\n",
    "def bruteforce(imputers, outlier_handlers, scalers, transformers, feature_selections, classifiers):\n",
    "    global evaluated_models, good_preprocessor_count, good_classifier_count\n",
    "    evaluated_models = []\n",
    "    good_preprocessor_count = 0\n",
    "    good_classifier_count = 0\n",
    "\n",
    "    preprocessors = []\n",
    "    for imputer in imputers:\n",
    "        for outlier_handler in outlier_handlers:\n",
    "            for scaler in scalers:\n",
    "                for transformer in transformers:\n",
    "                    for feature_selection in feature_selections:\n",
    "                        preprocessor = Pipeline(steps=[\n",
    "                            ('imputer', imputer),\n",
    "                            ('outlier_handler', outlier_handler),\n",
    "                            ('scaler', scaler),\n",
    "                            ('transformer', transformer),\n",
    "                            ('feature_selection', feature_selection)\n",
    "                            ],\n",
    "                            verbose=False\n",
    "                        )\n",
    "                        preprocessors.append(preprocessor)\n",
    "\n",
    "    model_index = 0\n",
    "    best_train_score = 0\n",
    "    best_test_score = 0\n",
    "    for preprocessor in preprocessors:\n",
    "        print(f\"preprocessor {preprocessors.index(preprocessor)+1}/{len(preprocessors)}\")\n",
    "        try:\n",
    "            preprocessor.fit(X_raw_train, y_raw_train)\n",
    "\n",
    "            X_train_preprocessed = preprocessor.transform(X_raw_train)\n",
    "            X_train_preprocessed = pd.DataFrame(X_train_preprocessed, columns=X_raw_train.columns[preprocessor.named_steps['feature_selection'].get_support()], index=X_raw_train.index)\n",
    "\n",
    "            X_test_preprocessed = preprocessor.transform(X_raw_test)\n",
    "            X_test_preprocessed = pd.DataFrame(X_test_preprocessed, columns=X_raw_test.columns[preprocessor.named_steps['feature_selection'].get_support()], index=X_raw_test.index)\n",
    "\n",
    "            for classifier in classifiers:\n",
    "                print(f\"PREPROCESSOR GOOD: {preprocessor}\")\n",
    "                good_preprocessor_count += 1\n",
    "                \n",
    "                try:\n",
    "                    classifier.fit(X_train_preprocessed, y_raw_train)\n",
    "\n",
    "                    train_score = classifier.score(X_train_preprocessed, y_train)\n",
    "                    test_score = classifier.score(X_test_preprocessed, y_test)\n",
    "\n",
    "                    if train_score > best_train_score or test_score > best_test_score:\n",
    "                        model = Pipeline([\n",
    "                            ('preprocessor', preprocessor),\n",
    "                            ('classifier', classifier),\n",
    "                            ],\n",
    "                            verbose=False\n",
    "                        )\n",
    "                        \n",
    "                        delta = train_score - test_score\n",
    "                        y_pred = classifier.predict(X_test_preprocessed)\n",
    "                        accuracy = accuracy_score(y_raw_test, y_pred)\n",
    "                        precision = precision_score(y_raw_test, y_pred, average='weighted')\n",
    "                        recall = recall_score(y_raw_test, y_pred, average='weighted')\n",
    "                        \n",
    "                        evaluated_models.append({\n",
    "                            \"train\": train_score,\n",
    "                            \"test\": test_score,\n",
    "                            \"delta\": delta,\n",
    "                            \"index\": model_index,\n",
    "                            \"model\": model,\n",
    "                            \"accuracy\": accuracy,\n",
    "                            \"precision\": precision,\n",
    "                            \"recall\": recall,\n",
    "                        })\n",
    "\n",
    "                        if train_score > best_train_score:\n",
    "                            best_train_score = train_score\n",
    "                        if test_score > best_test_score:\n",
    "                            best_test_score = test_score\n",
    "\n",
    "                    model_index += 1\n",
    "                    \n",
    "                    print(f\"CLASSIFIER GOOD: {(classifier)}\")\n",
    "                    good_classifier_count += 1\n",
    "\n",
    "                except Exception as ee:\n",
    "                    print(f\"CLASSIFIER BAD : {classifier}\\n{ee}\")\n",
    "                    print(\"--------------------------------------------------------------------------------------------------\")\n",
    "                    model_index += 1\n",
    "                \n",
    "                print(\"--------------------------------------------------------------------------------------------------\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"PREPROCESSOR BAD : {preprocessor}\\n{e}\")\n",
    "            model_index += 2\n",
    "            print(\"--------------------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bruteforce(imputers, outlier_handlers, scalers, transformers, feature_selections, classifiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"good_preprocessor_count {good_preprocessor_count}\")\n",
    "print(f\"good_classifier_count   {good_classifier_count}\")\n",
    "print(f\"len(evaluated_models)   {len(evaluated_models)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_iteration_info_type_1():\n",
    "    global evaluated_models\n",
    "    evaluated_models = sorted(evaluated_models, key=lambda x: x['test'], reverse=True)\n",
    "    for i in range(len(evaluated_models)):\n",
    "        model = evaluated_models[i]\n",
    "        print('train   test    delta  accuracy  precision  recall')\n",
    "        print(f\"{model['train']*100:.2f}%  \", end='')\n",
    "        print(f\"{model['test']*100:.2f}%  \", end='')\n",
    "        print(f\"{model['delta']*100:.2f}%  \", end='')\n",
    "        print(f\"{model['accuracy']*100:.2f}%    \", end='')\n",
    "        print(f\"{model['precision']*100:.2f}%     \", end='')\n",
    "        print(f\"{model['recall']*100:.2f}%  \")\n",
    "        print(f\"preprocessor:{model['model'].steps[0]}\")\n",
    "        print(f\"classifier:{model['model'].steps[1]}\")\n",
    "        print('-------------------------------------------------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_iteration_info_type_2():\n",
    "    global evaluated_models\n",
    "    evaluated_models = sorted(evaluated_models, key=lambda x: x['test'], reverse=True)\n",
    "    for step_i in range(len(evaluated_models[0]['model'].steps[0][1].steps)):\n",
    "        for i in range(len(evaluated_models)):\n",
    "            model = evaluated_models[i]\n",
    "            print('train   test    delta  accuracy  precision  recall')\n",
    "            print(f\"{model['train']*100:.2f}%  \", end='')\n",
    "            print(f\"{model['test']*100:.2f}%  \", end='')\n",
    "            print(f\"{model['delta']*100:.2f}%  \", end='')\n",
    "            print(f\"{model['accuracy']*100:.2f}%    \", end='')\n",
    "            print(f\"{model['precision']*100:.2f}%     \", end='')\n",
    "            print(f\"{model['recall']*100:.2f}%  \")\n",
    "            print(model['model'].steps[0][1].steps[step_i])\n",
    "            print()\n",
    "        print('--------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_iteration_info_type_3():\n",
    "    global evaluated_models\n",
    "    evaluated_models = sorted(evaluated_models, key=lambda x: x['delta'], reverse=False)\n",
    "    for step_i in range(len(evaluated_models[0]['model'].steps[0][1].steps)):\n",
    "        for i in range(len(evaluated_models)):\n",
    "            model = evaluated_models[i]\n",
    "            print('train   test    delta  accuracy  precision  recall')\n",
    "            print(f\"{model['train']*100:.2f}%  \", end='')\n",
    "            print(f\"{model['test']*100:.2f}%  \", end='')\n",
    "            print(f\"{model['delta']*100:.2f}%  \", end='')\n",
    "            print(f\"{model['accuracy']*100:.2f}%    \", end='')\n",
    "            print(f\"{model['precision']*100:.2f}%     \", end='')\n",
    "            print(f\"{model['recall']*100:.2f}%  \")\n",
    "            print(model['model'].steps[0][1].steps[step_i])\n",
    "            print()\n",
    "        print('--------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_iteration_info_type_1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_iteration_info_type_2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_iteration_info_type_3()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimal model from iteration 1:\n",
    "\n",
    "```py\n",
    "train: 89.03%  test:87.73%  delta:1.30%  \n",
    "preprocessor:('preprocessor', Pipeline(steps=[('imputer', SimpleImputer()),\n",
    "                ('outlier_handler',\n",
    "                 OutlierHandler(outlier_fraction=0.1, threshold=2.0)),\n",
    "                ('scaler', MinMaxScaler()), ('transformer', PowerTransformer()),\n",
    "                ('feature_selection', VarianceThreshold(threshold=0.1))]))\n",
    "classifier:('classifier', SVC(kernel='linear', random_state=42))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____________________________________________________________________________________\n",
    "**Iteration 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputers2 = [\n",
    "    SimpleImputer(),\n",
    "]\n",
    "\n",
    "outlier_handlers2 = [\n",
    "    OutlierHandler(threshold=2.0, outlier_fraction=0.1)\n",
    "]\n",
    "\n",
    "scalers2 = [\n",
    "    MinMaxScaler(),\n",
    "    RobustScaler()\n",
    "]\n",
    "\n",
    "transformers2 = [\n",
    "    PowerTransformer(method='yeo-johnson'),\n",
    "]\n",
    "\n",
    "feature_selections2 = [\n",
    "    SelectKBest(mutual_info_regression, k=5),\n",
    "    SelectKBest(f_regression, k=5),\n",
    "    VarianceThreshold(threshold=0.1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers2 = [\n",
    "    svc_model,\n",
    "    tuning_model,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bruteforce(imputers2, outlier_handlers2, scalers2, transformers2, feature_selections2, classifiers2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_iteration_info_type_1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_iteration_info_type_2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_iteration_info_type_3()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimal model from iteration 2:\n",
    "\n",
    "train   test    delta\n",
    "\n",
    "91.85%  90.20%  1.65%\n",
    "\n",
    "```py\n",
    "preprocessor:('preprocessor', Pipeline(steps=[('imputer', SimpleImputer()),\n",
    "                ('outlier_handler',\n",
    "                 OutlierHandler(outlier_fraction=0.1, threshold=2.0)),\n",
    "                ('scaler', MinMaxScaler()), ('transformer', PowerTransformer()),\n",
    "                ('feature_selection', VarianceThreshold(threshold=0.1))]))\n",
    "classifier:('classifier', SVC(random_state=42))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputers3 = [\n",
    "    SimpleImputer(),\n",
    "]\n",
    "\n",
    "outlier_handlers3 = [\n",
    "    OutlierHandler(threshold=2.0, outlier_fraction=0.1)\n",
    "]\n",
    "\n",
    "scalers3 = [\n",
    "    MinMaxScaler(),\n",
    "    RobustScaler()\n",
    "]\n",
    "\n",
    "transformers3 = [\n",
    "    PowerTransformer(method='yeo-johnson'),\n",
    "]\n",
    "\n",
    "feature_selections3 = [\n",
    "    SelectKBest(mutual_info_regression, k=7),\n",
    "    SelectKBest(mutual_info_regression, k=9),\n",
    "    SelectKBest(mutual_info_regression, k=11),\n",
    "    SelectKBest(mutual_info_regression, k=13),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers3 = [\n",
    "    tuning_model,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bruteforce(imputers3, outlier_handlers3, scalers3, transformers3, feature_selections3, classifiers3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_iteration_info_type_1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_iteration_info_type_2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_iteration_info_type_3()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimal model from iteration 3:\n",
    "\n",
    "train   test    delta\n",
    "\n",
    "91.85%  90.10%  1.75%\n",
    "\n",
    "```py\n",
    "preprocessor:('preprocessor', Pipeline(steps=[('imputer', SimpleImputer()),\n",
    "                ('outlier_handler',\n",
    "                 OutlierHandler(outlier_fraction=0.1, threshold=2.0)),\n",
    "                ('scaler', MinMaxScaler()), ('transformer', PowerTransformer()),\n",
    "                ('feature_selection',\n",
    "                 SelectKBest(k=11,\n",
    "                             score_func=<function mutual_info_regression at 0x0000015DD0FB5800>))]))\n",
    "classifier:('classifier', SVC(C=10, gamma=0.1))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputers4 = [\n",
    "    SimpleImputer(),\n",
    "]\n",
    "\n",
    "outlier_handlers4 = [\n",
    "    OutlierHandler(threshold=2.5, outlier_fraction=0.1),\n",
    "    OutlierHandler(threshold=2.5, outlier_fraction=0.05),\n",
    "    OutlierHandler(threshold=3.0, outlier_fraction=0.1),\n",
    "    OutlierHandler(threshold=3.0, outlier_fraction=0.05),\n",
    "]\n",
    "\n",
    "scalers4 = [\n",
    "    MinMaxScaler(),\n",
    "    RobustScaler()\n",
    "]\n",
    "\n",
    "transformers4 = [\n",
    "    PowerTransformer(method='yeo-johnson'),\n",
    "]\n",
    "\n",
    "feature_selections4 = [\n",
    "    SelectKBest(mutual_info_regression, k=11),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers4 = [\n",
    "    tuning_model,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bruteforce(imputers4, outlier_handlers4, scalers4, transformers4, feature_selections4, classifiers4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_iteration_info_type_1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_iteration_info_type_2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_iteration_info_type_3()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimal model from iteration 4:\n",
    "\n",
    "train   test    delta\n",
    "\n",
    "92.33%  90.67%  1.66%\n",
    "\n",
    "```py\n",
    "preprocessor:('preprocessor', Pipeline(steps=[('imputer', SimpleImputer()),\n",
    "                ('outlier_handler', OutlierHandler(threshold=3.0)),\n",
    "                ('scaler', RobustScaler()), ('transformer', PowerTransformer()),\n",
    "                ('feature_selection',\n",
    "                 SelectKBest(k=11,\n",
    "                             score_func=<function mutual_info_regression at 0x0000015DD0FB5800>))]))\n",
    "classifier:('classifier', SVC(C=10, gamma=0.1))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____________________________________________________________________________________\n",
    "**Iteration 5**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we commented out the ones with worst scores so the broteforce doesnt run so long\n",
    "\n",
    "imputers5 = [\n",
    "    SimpleImputer(strategy='mean'),\n",
    "    # SimpleImputer(strategy='median'),\n",
    "    # KNNImputer(n_neighbors=5)\n",
    "]\n",
    "\n",
    "outlier_handlers5 = [\n",
    "    # OutlierHandler(threshold=1.5, outlier_fraction=0.05),\n",
    "    OutlierHandler(threshold=2.0, outlier_fraction=0.1),\n",
    "    OutlierHandler(threshold=3.0, outlier_fraction=0.05)\n",
    "]\n",
    "\n",
    "scalers5 = [\n",
    "    MinMaxScaler(),\n",
    "    # StandardScaler(),\n",
    "    # RobustScaler()\n",
    "]\n",
    "\n",
    "transformers5 = [\n",
    "    PowerTransformer(method='yeo-johnson'),\n",
    "    # QuantileTransformer(output_distribution='normal'),\n",
    "    # QuantileTransformer(output_distribution='uniform')\n",
    "]\n",
    "\n",
    "feature_selections5 = [\n",
    "    SelectKBest(mutual_info_regression, k=5),\n",
    "    SelectKBest(f_regression, k=5),\n",
    "    SelectKBest(mutual_info_regression, k=11),\n",
    "    SelectKBest(f_regression, k=11),\n",
    "    # SelectKBest(f_classif, k=5),\n",
    "    # SelectKBest(chi2, k=5),\n",
    "    VarianceThreshold(threshold=0.1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers5 = [\n",
    "    # DecisionTreeClassifier(random_state=42),\n",
    "    # RandomForestClassifier(random_state=42),\n",
    "    # svc_model,\n",
    "    # tuning_model,\n",
    "    tuning_model_new,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bruteforce(imputers5, outlier_handlers5, scalers5, transformers5, feature_selections5, classifiers5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"good_preprocessor_count {good_preprocessor_count}\")\n",
    "print(f\"good_classifier_count   {good_classifier_count}\")\n",
    "print(f\"len(evaluated_models)   {len(evaluated_models)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_iteration_info_type_1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_iteration_info_type_2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_iteration_info_type_3()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimal model from iteration 5:\n",
    "\n",
    "train   test    delta\n",
    "\n",
    "92.31%  89.83%  2.48%\n",
    "\n",
    "```py\n",
    "preprocessor:('preprocessor', Pipeline(steps=[('imputer', SimpleImputer()),\n",
    "                ('outlier_handler', OutlierHandler(threshold=3.0)),\n",
    "                ('scaler', MinMaxScaler()), ('transformer', PowerTransformer()),\n",
    "                ('feature_selection', VarianceThreshold(threshold=0.1))]))\n",
    "classifier:('classifier', RandomForestClassifier(max_depth=10, min_samples_leaf=5, n_estimators=200,\n",
    "                       n_jobs=-1, random_state=42))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4.A Stratégie riešenia chýbajúcich hodnôt a outlierov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chýbajúce hodnoty sme vždy dokázali nahradiť použitím `SimpleImputer`, pričom stačilo použiť stratégiu mean (priemer).\n",
    "Najlepšie riešenie outlierov bolo, že sme zvýšili prahovú hodnotu (threshold). Ak dáta mali pár outlierov, tak model lepšie generalizoval."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4.B Dátová transformácia (scaling, transformer, …)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pri použití `RobustScaler` a `MinMaxScaler` boli výsledky modelov na podobnej úrovni, ale najlepšie modely využívali `MinMaxScaler`. `StandardScaler` takmer žiadny model nepoužil.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4.C Výber atribútov, výber algoritmov, hyperparameter tuning, ensemble learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Náš pôvodný výber príznakov (feature selection) bol k = 5, ale keď sme ho zvýšili na k = 11, zlepšila sa úspešnosť modelu. Pri väčších hodnotách `k` už ku zlepšeniu nedošlo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4.D Ktorý model je Váš najlepší model pre nasadenie (deployment)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Z bruteforce sme zistili, že nasledujúci pipeline a model resp. klasifikátor je najlepší pre nasadenie do produkcie (deployment):\n",
    "\n",
    "| Train   | Test   | Delta   | Accuracy | Precision | Recall |\n",
    "|---------|--------|---------|----------|-----------|--------|\n",
    "| 92.30%  | 90.70% | 1.60%   | 90.70%   | 90.70%    | 90.70% |\n",
    "\n",
    "\n",
    "```py\n",
    "preprocessor:('preprocessor', Pipeline(steps=[('imputer', SimpleImputer()),\n",
    "                ('outlier_handler', OutlierHandler(threshold=3.0)),\n",
    "                ('scaler', MinMaxScaler()), ('transformer', PowerTransformer()),\n",
    "                ('feature_selection',\n",
    "                 SelectKBest(k=11,\n",
    "                             score_func=<function mutual_info_regression at 0x000001B52CA73100>))]))\n",
    "classifier:('classifier', SVC(C=10, gamma=0.1))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4.E Aký je data pipeline pre jeho vybudovanie na základe Vášho datasetu v produkcii?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okrem modelu sme vyššie v sekcii `3.4.D` už spomenuli aj pipeline, ktorý sme použili na vytvorenie nášho najlepšieho modelu. Tento pipeline by sme mohli použiť aj v produkcii, pretože je najlepší zo všetkých, ktoré sme skúšali v bruteforce."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Záver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naše lepšie modeli v sekciách `3.1` až `3.3` boli relatívne dobré, pretože väčšinou nemali ani underfit ani overfit a boli stabilné, čo sme zistili z metrík accuracy, precision a recall. Avšak nemali takú vysokú úspešnosť ako sme si nazačiatku predstavovali. Neboli sme vlastne spokojný s úspešnosťou modelov, čoho príčinou bolo asi nie optimálne predspracovanie v druhej fáze. Preto sme sa rozhodli, že pomocou nejakej inteligentnej kombinácie bruteforcu, analýzy a greedy algoritmov zostrojíme najlepší pipeline a zároveň klasifikačný model, ktorý bude mať najlepšiu úspešnosť a nebude mať ani underfit ani overfit, čo sa nám vlastne podarilo.\n",
    "\n",
    "Z pôvodných modelov, ktoré mali úspešnosť `~83%` sa nám podarilo vytvoriť model, ktorý má úspešnosť `~91%`, čo je veľký rozdiel a zlepšenie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zdroje"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prednášky a cvičenia z predmetu IAU.\n",
    "\n",
    "[IAU Github repozitár](https://github.com/FIIT-IAU/IAU-course)\n",
    "\n",
    "[Scipy dokumentácia](https://docs.scipy.org/doc/scipy/reference/index.html)\n",
    "\n",
    "[Numpy dokumentácia](https://numpy.org/doc/)\n",
    "\n",
    "[Pandas dokumentácia](https://pandas.pydata.org/docs/)\n",
    "\n",
    "[Typical Analysis Procedure](https://work.thaslwanter.at/Stats/html/statsAnalysis.html)\n",
    "\n",
    "\n",
    "[Scikit-learn dokumentácia](https://scikit-learn.org/1.5/api/index.html)\n",
    "\n",
    "[Feature importance](https://machinelearningmastery.com/calculate-feature-importance-with-python/)\n",
    "\n",
    "[Scaling](https://machinelearningmastery.com/standardscaler-and-minmaxscaler-transforms-in-python/)\n",
    "\n",
    "[Transformations](https://machinelearningmastery.com/power-transforms-with-scikit-learn/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
