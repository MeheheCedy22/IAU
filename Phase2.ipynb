{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IAU - Inteligentná analýza údajov (2024/2025)\n",
    "\n",
    "#### Autori: Jan Lenhart (50 %), Marek Čederle (50 %)\n",
    "##### Cvičenie: Pondelok 15:00, Cvičiaci: Ing. Oleksandr Lytvyn\n",
    "\n",
    "<font color='salmon'>\n",
    "    <b>Poznámka:</b>\n",
    "    Fáza 1 - boli zachované nejaké časti, funkcie a knižnice, ktoré nám boli užitočné pri fáze 2, pri prezeraní fázy 2 je vhodné si fázu 1 zbaliť\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fáza 1 - Prieskumná analýza"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na začiatok si importujeme knižnice a načítame dáta, do dátových rámcov (dataframov)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import copy\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.width\", 2**20)\n",
    "pd.set_option(\"display.max_columns\", 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_connections = pd.read_csv('112/connections.csv', delimiter=',')\n",
    "df_processes   = pd.read_csv('112/processes.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMEI je unikátny identifikátor mobilného zariadenia, ktorý sa nachádza vo všetkých rámcoch, takže ho bude možné použiť ako primárny kľúč na spájanie tabuliek, ak to bude neskôr potrebné."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_normality_test(df):\n",
    "    if df.count() > 5000:\n",
    "        stat, p_value = stats.kstest(df, 'norm')\n",
    "        print(f\"kstest for count={df.count()}: [stat: {stat}, p: {p_value}, norm: {p_value > 0.05}]\")\n",
    "    else:\n",
    "        stat, p_value = stats.shapiro(df)\n",
    "        print(f\"stat: for count={df.count()}: [stat: {stat}, p: {p_value}, norm: {p_value > 0.05}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_normality_test(df_connections[\"c.katana\"])\n",
    "print_normality_test(df_connections[\"c.android.gm\"])\n",
    "print_normality_test(df_connections[\"c.android.chrome\"])\n",
    "print_normality_test(df_connections[\"c.dogalize\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Počet záznamov je väčší ako 5000, preto bol použitý Kolmogorov-Smirnov (`kstest`) namiesto Shapiro-Wilk z ktorého vyplíva, že dáta vo vybraných stĺpcoch nespĺňajú normálovú distribúciu pretože p-hodnota je menšia ako 0.05."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_normality_test(df_processes[\"p.android.gm\"])\n",
    "print_normality_test(df_processes[\"p.system\"])\n",
    "print_normality_test(df_processes[\"p.android.chrome\"])\n",
    "print_normality_test(df_processes[\"p.browser.provider\"])\n",
    "print_normality_test(df_processes[\"p.android.documentsui\"])\n",
    "print_normality_test(df_processes[\"p.android.packageinstaller\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_predictor = 'mwra'\n",
    "strong_predictors = pd.DataFrame()\n",
    "moderate_predictors = pd.DataFrame()\n",
    "weak_predictors = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_prediction(df):\n",
    "    global strong_predictors, moderate_predictors, weak_predictors\n",
    "    numerical_columns = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "    corr_matrix = df[numerical_columns].corr()\n",
    "    corrs = corr_matrix[[target_predictor]].sort_values(by=target_predictor, ascending=False)\n",
    "    corrs = corrs.drop('mwra')\n",
    "    sns.heatmap(corrs, annot=True, cmap='coolwarm')\n",
    "    plt.title(f'Correlation of {target_predictor} with numerical predictors')\n",
    "    plt.show()\n",
    "    strong_predictors = pd.concat([strong_predictors, pd.DataFrame(np.where(abs(corrs) > 0.7, corrs, np.nan), columns=corrs.columns, index=corrs.index).dropna()])\n",
    "    moderate_predictors = pd.concat([moderate_predictors, pd.DataFrame(np.where((abs(corrs) > 0.5) & (abs(corrs) <= 0.7), corrs, np.nan), columns=corrs.columns, index=corrs.index).dropna()])\n",
    "    weak_predictors = pd.concat([weak_predictors, pd.DataFrame(np.where((abs(corrs) > 0.25) & (abs(corrs) <= 0.5), corrs, np.nan), columns=corrs.columns, index=corrs.index).dropna()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funkcia `numerical_prediction` získa prediktory pre dátový rámec, ktorý dostane ako parameter. Získané prediktory akumuluje do globálnych premenných `strong_predictors`, `moderate_predictors` a `weak_predictors`. To sú kategorizované premenné, ktoré v páre so stĺpcom `mwra` majú koreláciu viac ako `0.7` pre `strong`, viac ako `0.5` a menej ako `0.7` pre `moderate` a viac ako `0.25` (bolo by lepšie, keby toto číslo bolo 0.3, ale chceli sme zvýšiť počet prediktorov a ak budú dávať zlé výsledky, môžeme ich kedykoľvek vyhodiť) a menej ako `0.5` pre `weak`. Taktiež, pri volaní zobrazí heatmapu vypočítaných korelácií, aby poskytla vizuálny prehľad o vzťahoch medzi premennými."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_prediction(df_connections)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tento graf nám hovorí o tom, ktoré premenné z dátového rámca `df_connections` korelujú s našou predikovanou premennou `mwra`.\n",
    "Môžeme vidieť že stĺpce `c.dogalize`, `c.android.chrome` a `c.katana` majú najvyššiu koreláciu s predikovanou premennou `mwra`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_prediction(df_processes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tento graf nám hovorí o tom, ktoré premenné z dátového rámca `df_processes` korelujú s našou predikovanou premennou `mwra`.\n",
    "Môžeme vidieť že stĺpce `p.android.gm`, `p.system`, `p.android.chrome`, `p.android.documentsui` a `p.android.packageinstaller` majú najvyššiu koreláciu s predikovanou premennou `mwra`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(strong_predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(moderate_predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(weak_predictors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tu môžeme vidieť že nemáme žiadne silné predikátory (korelácia `> 0.7`).\n",
    "Máme však stredne silné a slabšie predikátory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.E Zamyslenie k riešeniu projektu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pomocou párovej analýzi sme zistili nejakú koreláciu resp. závisloť premenných. Konkrétne mali najsilnejšiu koreláciu s predikovanou premennou `mwra` tieto stĺpce:\n",
    "- c.dogalize\n",
    "- p.android.gm\n",
    "- p.android.packageinstaller\n",
    "\n",
    "Kedže sa nachádzajú v iných dátových rámcoch, bude potrebné ich spojiť pomocou `imei`.\n",
    "\n",
    "Podľa toho, ako dáta vyzerajú a čo sme zistili, tak si myslíme že ide o nejaké využitie CPU s tým že CPU môže mať viacero jadier a preto hodnoty premenných nedávajú súčet 100 ale viacej čo by znamenalo že by mohlo ísť o viacej jadrové CPU (napr. 8), ale toto je iba naša teória.\n",
    "\n",
    "Je vysoko pravdepodobné že bude treba spájať dané dáta pretože aj `devices.csv` aj `processes.csv` majú stĺpec `mwra` a budeme muset zistit koreláciu naprieč týmito dátami."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Identifikácia problémov, integrácia a čistenie dát"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.A Identifikácia a prvotné riešenie problémov v dátach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connections_string_columns = set(copy(df_connections.select_dtypes(include=['object']).columns))\n",
    "processes_string_columns = set(copy(df_processes.select_dtypes(include=['object']).columns))\n",
    "string_columns = list(connections_string_columns | processes_string_columns)\n",
    "print(string_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Vymazanie duplikátov v dátach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicates(df):\n",
    "    pre_count = df.duplicated().count()\n",
    "    df = df.drop_duplicates()\n",
    "    post_count = df.duplicated().count()\n",
    "    print(f\"removed {pre_count - post_count} duplicates\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_connections = remove_duplicates(df_connections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processes = remove_duplicates(df_processes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.B Chýbajúce hodnoty (missing values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printNonesAndNA(label, df):\n",
    "    nulls = df.isnull().sum()\n",
    "    if (nulls.sum()):\n",
    "        df_temp = pd.DataFrame(np.where(nulls > 0, nulls, np.nan), index=nulls.index, columns=['null_count']).dropna()\n",
    "        df_temp['percentage'] = df_temp.apply(lambda x: x / df.shape[0] * 100)\n",
    "        print(label)\n",
    "        print(df_temp)\n",
    "        print()\n",
    "        return df_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printNonesAndNA(\"df_connections\", df_connections)\n",
    "printNonesAndNA(\"df_processes\", df_processes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.C Vychýlené hodnoty (outlier detection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na ukážku si vykreslíme boxploty pre vybrané atribúty a zistíme, či sa v nich nachádzajú nejaké vychýlené hodnoty. Naše atribúty sú premenné, ktoré najviac korelovali s predikovanou premennou `mwra` a teda sú to:\n",
    "- c.dogalize\n",
    "- p.android.gm\n",
    "- p.android.packageinstaller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x='mwra', y='c.dogalize', data=df_connections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x='mwra', y='p.android.gm', data=df_processes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x='mwra', y='p.android.packageinstaller', data=df_processes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Následne identifikujeme outlierov pomocou IQR metódy a overíme že ich skutočne máme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zdroj z cvicenia\n",
    "def identify_outliers(data):\n",
    "    lower = data.quantile(0.25) - 1.5 * stats.iqr(data)\n",
    "    upper = data.quantile(0.75) + 1.5 * stats.iqr(data)\n",
    "    return data[(data > upper) | (data < lower)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_outliers_for_all_columns(df):\n",
    "    val = {}\n",
    "    columns = df.select_dtypes(exclude=['object']).columns\n",
    "    for column in columns:\n",
    "        outlier_count = identify_outliers(df[column]).count()\n",
    "        if outlier_count > 0:\n",
    "            val[column] = outlier_count\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "identify_outliers_for_all_columns(df_connections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "identify_outliers_for_all_columns(df_processes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zistili sme že ich máme relatívne málo vzhľadom na počet záznamov, takže ich môžeme odstrániť."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers_for_all_columns(df):\n",
    "    df_temp = df.copy()\n",
    "    indices = pd.DataFrame({})\n",
    "    accumulated_indices = set()\n",
    "    for column in df_temp.select_dtypes(exclude=['object']).columns:\n",
    "        accumulated_indices |= set(identify_outliers(df_temp[column]).index)\n",
    "    df_temp = df_temp.drop(accumulated_indices)\n",
    "    return df_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_connections = remove_outliers_for_all_columns(df_connections)\n",
    "df_processes = remove_outliers_for_all_columns(df_processes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ostránime iba outlierov z dátového rámca `df_processes` a `df_connections` pretože, v dátovom rámci `df_devices` a `df_profiles` nemáme žiadne numerické hodnoty, s ktorými je vhodné pracovať. (Zemepisné súradnice a unikátne identifikátory)\n",
    "Po odstránení outlierov si možeme znova identifikovať či náhodou nejakých ešte nemáme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "identify_outliers_for_all_columns(df_connections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "identify_outliers_for_all_columns(df_processes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zistili sme že napriek úvodnému odstráneniu mám stále outlierov. Deje sa to z toho dôvodu, že sa vlastne distibúcia posunie a preto sa nám objavili nový outliery. Keby takto pokračujeme a odstraňujeme stále dáta, tak by sme prišli o veľký počet záznamov a preto sme sa rozhodli ich nahradiť hraničnými hodnotami (5% a 95%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x='mwra', y='p.browser.provider', data=df_processes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(df_processes['p.browser.provider'], kde=True, color='blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_outliers_with_percentiles(df):\n",
    "    df_temp = df.copy()\n",
    "    for column in df_temp.select_dtypes(exclude=['object']).columns:\n",
    "        lower_bound = df_temp[column].quantile(0.05)\n",
    "        upper_bound = df_temp[column].quantile(0.95)\n",
    "        lower_outliers = df_temp[column] < lower_bound\n",
    "        upper_outliers = df_temp[column] > upper_bound\n",
    "        df_temp.loc[lower_outliers, column] = lower_bound\n",
    "        df_temp.loc[upper_outliers, column] = upper_bound\n",
    "    return df_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_connections = replace_outliers_with_percentiles(df_connections)\n",
    "df_processes = replace_outliers_with_percentiles(df_processes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "identify_outliers_for_all_columns(df_connections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "identify_outliers_for_all_columns(df_processes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram\n",
    "sns.histplot(df_processes['p.browser.provider'], kde=True, color='blue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ako vidíme z výpisu dát, tak sa nám podarilo všetkých outlierov bud odstrániť alebo nahradiť hraničnými hodnotami.\n",
    "Jedniou výnimkou je `p.browser.provider` a to z dôvodu ako vyzerá jeho distribúcia. Preto sme sa rozhodli to nemeniť, pretože by sme pri iteratívnom odstraňovaní prišli o veľký počet záznamov."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Formulácia a štatistické overenie hypotéz o dátach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.A Formulácia hypotéz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Hypotéza č.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zvolíme si náš \"significance level\" na $\\alpha = 0.05$. (95%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Null hypothesis (nulová hypotéza):\n",
    "\n",
    "$H_0$: Premenná `p.android.gm` má v priemere rovnakú váhu v stave malware-related-activity ako v normálnom stave.\n",
    "\n",
    "Alternative hypothesis (alternatívna hypotéza):\n",
    "$H_1$ = $H_A$: Premenná `p.android.gm` má v priemere inú váhu v stave malware-related-activity ako v normálnom stave. (Nižšiu alebo vyššiu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Najskôr si musíme overiť či dáta spĺňajú normálovú distribúciu**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Takto vyzerá náš boxplot, ktorý nám ukazuje distribúciu hodnôt pre premennú `p.android.gm` v závislosti od `mwra`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x='mwra', y='p.android.gm', data=df_processes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_android_gm_0 = df_processes.loc[df_processes.mwra == 0, 'p.android.gm']\n",
    "p_android_gm_0.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(p_android_gm_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_android_gm_1 = df_processes.loc[df_processes.mwra == 1, 'p.android.gm']\n",
    "p_android_gm_1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(p_android_gm_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Z týchto distribúcií môžeme vidieť, že nevyzerajú ako normálne distribúcie, preto musíme pokračovať s overením."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_android_gm_0_outliers = identify_outliers(p_android_gm_0)\n",
    "p_android_gm_1_outliers = identify_outliers(p_android_gm_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_android_gm_0_outliers.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_android_gm_1_outliers.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_android_gm_0 = p_android_gm_0.drop(p_android_gm_0_outliers.index)\n",
    "p_android_gm_1 = p_android_gm_1.drop(p_android_gm_1_outliers.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(p_android_gm_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vidíme že aj po vyhodení outlierov sa nám distribúcia nezmenila a preto môžeme pokračovať s testovaním."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = sm.ProbPlot(p_android_gm_0, fit=True).qqplot(line='45')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = sm.ProbPlot(p_android_gm_1, fit=True).qqplot(line='45')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ani `QQ-plot` nám nepotvrdil normálnu distribúciu. Pretože aby bola distribúcia normálna, tak by sa body museli nachádzať na priamke definovanej ako $x=y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_android_gm_0.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_android_gm_1.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Musíme použiť štatistický test, ktorý nám povie či dáta majú normálnu distribúciu alebo nie. Použijeme `Kolmogorov-Smirnov` test namiesto `Shapiro-Wilk` pretože počet záznamov je väčší ako 5000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_normality_test(p_android_gm_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_normality_test(p_android_gm_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Výsledok testu nám potvrdil, že dáta nemajú normálnu distribúciu, preto musíme použiť neparametrický test na overenie hypotézy. Pretože p hodnota je menšia ako 0.05."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Použijeme `Mann-Whitney U Test` pretože máme práve dve premenné a zároveň spĺňajú predpoklady pre tento test (vzorka musí byť aspoň 20)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.mannwhitneyu(p_android_gm_0, p_android_gm_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keďže nám vyšlo p menšie ako 0.05 tak zamietame nulovú hypotézu a prijímame alternatívnu hypotézu, že premenná `p.android.gm` má v priemere inú váhu v stave malware-related-activity ako v normálnom stave."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Hypotéza č.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zvolíme si náš \"significance level\" na $\\alpha = 0.05$. (95%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Null hypothesis (nulová hypotéza):\n",
    "\n",
    "$H_0$: Premenná `p.android.packageinstaller` má v priemere rovnakú váhu v stave malware-related-activity ako v normálnom stave.\n",
    "\n",
    "Alternative hypothesis (alternatívna hypotéza):\n",
    "$H_1$ = $H_A$: Premenná `p.android.packageinstaller` má v priemere inú váhu v stave malware-related-activity ako v normálnom stave. (Nižšiu alebo vyššiu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Najskôr si musíme overiť či dáta spĺňajú normálovú distribúciu**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Takto vyzerá náš boxplot, ktorý nám ukazuje distribúciu hodnôt pre premennú `p.android.packageinstaller` v závislosti od `mwra`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x='mwra', y='p.android.packageinstaller', data=df_processes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_android_packageinstaller_0 = df_processes.loc[df_processes.mwra == 0, 'p.android.packageinstaller']\n",
    "p_android_packageinstaller_0.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(p_android_packageinstaller_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_android_packageinstaller_1 = df_processes.loc[df_processes.mwra == 1, 'p.android.packageinstaller']\n",
    "p_android_packageinstaller_1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(p_android_packageinstaller_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Z týchto distribúcií môžeme vidieť, že nevyzerajú ako normálne distribúcie, preto musíme pokračovať s overením."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_android_packageinstaller_0_outliers = identify_outliers(p_android_packageinstaller_0)\n",
    "p_android_packageinstaller_1_outliers = identify_outliers(p_android_packageinstaller_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_android_packageinstaller_0_outliers.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_android_packageinstaller_1_outliers.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_android_packageinstaller_0 = p_android_packageinstaller_0.drop(p_android_packageinstaller_0_outliers.index)\n",
    "p_android_packageinstaller_1 = p_android_packageinstaller_1.drop(p_android_packageinstaller_1_outliers.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(p_android_packageinstaller_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(p_android_packageinstaller_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vidíme že aj po vyhodení outlierov sa nám distribúcia nezmenila a preto môžeme pokračovať s testovaním."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = sm.ProbPlot(p_android_packageinstaller_0, fit=True).qqplot(line='45')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = sm.ProbPlot(p_android_packageinstaller_1, fit=True).qqplot(line='45')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ani `QQ-plot` nám nepotvrdil normálnu distribúciu. Pretože aby bola distribúcia normálna, tak by sa body museli nachádzať na priamke definovanej ako $x=y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_android_packageinstaller_0.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_android_packageinstaller_1.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Musíme použiť štatistický test, ktorý nám povie či dáta majú normálnu distribúciu alebo nie. Použijeme `Shapiro-Wilk` test pre jednu premennú a `Kolmogorov-Smirnov` pre druhú premennú pretože pri jednej je počet záznamov je nižší ako 5000 a pri druhej vyšší."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shapiro-Wilk test\n",
    "print_normality_test(p_android_packageinstaller_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kolmogorov-Smirnov test\n",
    "print_normality_test(p_android_packageinstaller_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Výsledok testu nám potvrdil, že dáta nemajú normálnu distribúciu, preto musíme použiť neparametrický test na overenie hypotézy. Pretože p hodnota je menšia ako 0.05."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Použijeme `Mann-Whitney U Test` pretože máme práve dve premenné a zároveň spĺňajú predpoklady pre tento test (vzorka musí byť aspoň 20)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.mannwhitneyu(p_android_packageinstaller_0, p_android_packageinstaller_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keďže nám vyšlo p menšie ako 0.05 tak zamietame nulovú hypotézu a prijímame alternatívnu hypotézu, že premenná `p.android.packageinstaller` má v priemere inú váhu v stave malware-related-activity ako v normálnom stave."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.B Overenie štatistickej sily"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kedže nám p values vyšli všetky menšie ako 0.001, tak môžeme povedať že naše testy mali veľkú štatistickú silu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fáza 2 - Predspracovanie údajov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_connections = pd.read_csv('112/connections.csv', delimiter=',')\n",
    "df_processes   = pd.read_csv('112/processes.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Realizácia predspracovania dát"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.A Dáta si rozdeľte na trénovaciu a testovaciu množinu podľa vami preddefinovaného pomeru. Ďalej pracujte len s trénovacím datasetom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data = df_connections.merge(df_processes, on=['imei', 'ts'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data['ts'] = pd.to_numeric(pd.to_datetime(merged_data['ts'], errors='coerce'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Po načítaní datasetov z `.csv` súborov sme si ich spojili na základe spoločného stĺpca `imei` a `ts` a upravili sme dátový typ stĺpca `ts` aby sa nám s ním neskôr dalo pracovať.\n",
    "\n",
    "Na základe výsledkov a zistení vo fázy 1, sme použili iba datasety `processes.csv` a `connections.csv` pretože obsahujú numerické hodnoty, ktoré sú vhodné pre modelovanie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data.loc[merged_data['mwra_x'] != merged_data['mwra_y']]['imei'].count() / merged_data['imei'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data = merged_data.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data = merged_data.drop(columns=['mwra_y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data = merged_data.rename(columns={\"mwra_x\": \"mwra\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = merged_data.drop(columns='mwra')\n",
    "y = merged_data['mwra']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objavili sa nám 2 stĺpce `mwra`, tak smeoverili, či sú medyi nimi nejaké rozdiely, konkrétne `mwra_x` a `mwra_y` a zistili sme že sú rovnaké (bol to dôsledok joinu, pretože `mwra` sa nachádzala v oboch súboroch), preto sme jeden z nich odstránili.\n",
    "Následne sme si rozdelili naše dáta na trénovaciu a testovaciu časť podľa pomeru 80:20 (trénovacia : testovacia)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.B Transformujte dáta na vhodný formát pre ML t.j. jedno pozorovanie musí byť opísané jedným riadkom a každý atribút musí byť v numerickom formáte (encoding). zIteratívne integrujte aj kroky v predspracovaní dát z prvej fázy (missing values, outlier detection) ako celok. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Missing values (Chýbajúce hodnoty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_train_impute = imputer.fit_transform(X_train)\n",
    "X_train = pd.DataFrame(X_train_impute, columns=X_train.columns, index=X_train.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zistili sme, že nemáme žiadne missing values v našich dátach, avšak ako prípravu na pipeline sme si urobili `imputer`, ktorý by prípadné chýbajúce hodnoty nahradil za priemer (keďže nepracujeme s testovacím datasetom ale iba trénovacím).\n",
    "\n",
    "Keďže všetky naše hodnoty majú numerický formát, tak nemusíme robiť encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Handling outliers (Ošetrovanie outlierov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_outliers(X, y):\n",
    "    X_temp = X.copy()\n",
    "    indices_remove = set()\n",
    "    for column in X.columns:\n",
    "        outliers = identify_outliers(X[column])\n",
    "        if outliers.count() / X[column].count() < 0.05:\n",
    "            indices_remove.update(outliers.index)\n",
    "        \n",
    "    X_temp = X.drop(index=indices_remove)\n",
    "    y = y.drop(index=indices_remove)\n",
    "\n",
    "    X_temp = replace_outliers_with_percentiles(X_temp)\n",
    "    \n",
    "    return X_temp, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.count().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(X_train['p.browser.provider'], kde=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "identify_outliers_for_all_columns(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = handle_outliers(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.count().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "identify_outliers_for_all_columns(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(X_train['p.browser.provider'], kde=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outlierov sme vyriešili podobne ako v prvej fáze. Ak bol počet outlierov v jednom stĺpci vacčší ako 5% z celkového počtu záznamov, tak sme ich nahradili hraničnými hodnotami (5 a 95 percentil), ak boli menšie, tak sme ich odstránili. Na ukážku sme zobrazili graf premennej `p.browser.provider` a zistili sme že aj po odstránení outlierov, máme zase ďalších, ale ďaľej sme nepokračovali v ich odstraňovaní, pretože by sme prišli o veľký počet záznamov."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.C Transformujte atribúty dát pre strojové učenie podľa dostupných techník minimálne: scaling (2 techniky), transformers (2 techniky) a ďalšie. Cieľom je aby ste testovali efekty a vhodne kombinovali v dátovom pipeline (od časti 2.3 a v 3. fáze)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ukážka distribúcií našich dát pred škálovaním a transformáciou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moderate_predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weak_predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictor_distribution(in_df, series_mwra, predictors):\n",
    "    df = in_df.copy()\n",
    "    df['mwra'] = series_mwra\n",
    "    num_predictors = len(predictors)\n",
    "    fig, axes = plt.subplots(1, num_predictors, figsize=(5 * num_predictors, 5), sharey=True)  # sharey=True to share the y-axis scale\n",
    "    for i, predictor in enumerate(predictors.index):\n",
    "       sns.kdeplot(data=df, x=predictor, hue=\"mwra\", fill=True, common_norm=False, alpha=0.5, ax=axes[i])\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictor_distribution(merged_data, merged_data['mwra'], moderate_predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictor_distribution(merged_data, merged_data['mwra'], weak_predictors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Škálovanie (Scaling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vyskúšame viacej metód škálovania, a neskôr zistíme ktorá je pre nás najvhodnejšia v spojení s transformáciou."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_scaler = MinMaxScaler()\n",
    "X_train_normalized = min_max_scaler.fit_transform(X_train)\n",
    "X_train_normalized = pd.DataFrame(X_train_normalized, columns=X_train.columns, index=X_train.index)\n",
    "\n",
    "standard_scaler = StandardScaler()\n",
    "X_train_standardized = standard_scaler.fit_transform(X_train)\n",
    "X_train_standardized = pd.DataFrame(X_train_standardized, columns=X_train.columns, index=X_train.index)\n",
    "\n",
    "robust_scaler = RobustScaler()\n",
    "X_train_robust = robust_scaler.fit_transform(X_train)\n",
    "X_train_robust = pd.DataFrame(X_train_robust, columns=X_train.columns, index=X_train.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na ukážku používame naše predikátory z fázy 1, pretože predpokladáme že to budú najdôležitejšie premenné resp. črty (features)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Normalizácia dát (MinMaxScaler)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictor_distribution(X_train_normalized, y_train, moderate_predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictor_distribution(X_train_normalized, y_train, weak_predictors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Štandardizácia dát (StandardScaler)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictor_distribution(X_train_standardized, y_train, moderate_predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictor_distribution(X_train_standardized, y_train, weak_predictors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Robustné škálovanie (RobustScaler)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictor_distribution(X_train_robust, y_train, moderate_predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictor_distribution(X_train_robust, y_train, weak_predictors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grafy nám všake ukazujú distribúcie, ktoré by mohli byť podobné normálnej distribúcii (s nejakými výnimkami), avšak sú \"skewed\" a ich konce (tails) sú viacej špičaté, čo bolo spôsobné nahradením outlierov hraničnými hodnotami."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vyskúšame taktiež viacej metód transformovania pre každé škálovanie, a neskôr zistíme ktorá je pre nás najvhodnejšia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power_transformer = PowerTransformer(method='yeo-johnson')\n",
    "quantile_transformer = QuantileTransformer(n_quantiles=1000, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_normalized_power = power_transformer.fit_transform(X_train_normalized)\n",
    "X_train_normalized_quantile = quantile_transformer.fit_transform(X_train_normalized)\n",
    "\n",
    "X_train_standardized_power = power_transformer.fit_transform(X_train_standardized)\n",
    "X_train_standardized_quantile = quantile_transformer.fit_transform(X_train_standardized)\n",
    "\n",
    "X_train_robust_power = power_transformer.fit_transform(X_train_robust)\n",
    "X_train_robust_quantile = quantile_transformer.fit_transform(X_train_robust)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_normalized_power = pd.DataFrame(X_train_normalized_power, columns=X_train_normalized.columns, index=X_train_normalized.index)\n",
    "X_train_normalized_quantile = pd.DataFrame(X_train_normalized_quantile, columns=X_train_normalized.columns, index=X_train_normalized.index)\n",
    "X_train_standardized_power = pd.DataFrame(X_train_standardized_power, columns=X_train_standardized.columns, index=X_train_standardized.index)\n",
    "X_train_standardized_quantile = pd.DataFrame(X_train_standardized_quantile, columns=X_train_standardized.columns, index=X_train_standardized.index)\n",
    "X_train_robust_power = pd.DataFrame(X_train_robust_power, columns=X_train_robust.columns, index=X_train_robust.index)\n",
    "X_train_robust_quantile = pd.DataFrame(X_train_robust_quantile, columns=X_train_robust.columns, index=X_train_robust.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='#38C570'>\n",
    "    <b>\n",
    "        Transformácia dát (PowerTransformer), s normalizáciou dát (MinMaxScaler)\n",
    "    </b>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictor_distribution(X_train_normalized_power, y_train, moderate_predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictor_distribution(X_train_normalized_power, y_train, weak_predictors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Transformácia dát (QuantileTransformer), s normalizáciou dát (MinMaxScaler)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictor_distribution(X_train_normalized_quantile, y_train, moderate_predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictor_distribution(X_train_normalized_quantile, y_train, weak_predictors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Transformácia dát (PowerTransformer), s štandardizáciou dát (StandardScaler)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictor_distribution(X_train_standardized_power, y_train, moderate_predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictor_distribution(X_train_standardized_power, y_train, weak_predictors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Transformácia dát (QuantileTransformer), s štandardizáciou dát (StandardScaler)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictor_distribution(X_train_standardized_quantile, y_train, moderate_predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictor_distribution(X_train_standardized_quantile, y_train, weak_predictors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Transformácia dát (PowerTransformer), s robustným škálovaním (RobustScaler)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictor_distribution(X_train_robust_power, y_train, moderate_predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictor_distribution(X_train_robust_power, y_train, weak_predictors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Transformácia dát (QuantileTransformer), s robustným škálovaním (RobustScaler)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictor_distribution(X_train_robust_quantile, y_train, moderate_predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictor_distribution(X_train_robust_quantile, y_train, weak_predictors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.D Zdôvodnite Vaše voľby/rozhodnutie pre realizáciu (t.j. zdokumentovanie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_normalized_power.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vyskúšali sme si viacej kombinácií škálovania a transformácií. Rozhodli sme sa, že ďalej (neskôr do pipeline) použijeme `MinMaxScaler` na škálovanie a `PowerTransformer` na transformovanie dát. Je to z dôvodu, že `MinMaxScaler` škáluje dáta na jednotný rozsah (v našom prípade <0; 1>). Používa sa, keď nemáme žiadnych outlierov alebo už boli odstránené, čo je presne náš prípad. Síce máme stále nejakých outlierov v premennej `p.browser.provider`, ale tá neni našim predikátorom, takže by to nemalo ovplyvňovať naše výsledky. `PowerTransformer` sme si vybrali pretože vie transofrmovať dáta približne na normálnu distribúciu (blízko normálnej distribúcii), čo je vhodné pre niektoré ML (Machine Learning) modely, pretože to môže prinášať lepšie výsledky."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Výber atribútov pre strojové učenie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.A Zistite, ktoré atribúty (features) vo vašich dátach pre ML sú informatívne k predikovanej premennej (minimálne 3 techniky s porovnaním medzi sebou). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vyskúšame 3 metódy na výber čŕt, ktoré nám pomôžu zistiť, ktoré črty (features) sú najinformatívnejšie pre predikciu našej predikovanej premennej `mwra`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Mutual Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutual_info_regression_selector = SelectKBest(mutual_info_regression, k=5)\n",
    "X_train_featured_mutual_info_regression = mutual_info_regression_selector.fit_transform(X_train, y_train)\n",
    "X_train_featured_mutual_info_regression = pd.DataFrame(X_train_featured_mutual_info_regression, columns=X_train.columns[mutual_info_regression_selector.get_support()], index=X_train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_featured_mutual_info_regression.head(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### F-value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_regression_selector = SelectKBest(f_regression, k=5)\n",
    "X_train_featured_f_regression = f_regression_selector.fit_transform(X_train, y_train)\n",
    "X_train_featured_f_regression = pd.DataFrame(X_train_featured_f_regression, columns=X_train.columns[f_regression_selector.get_support()], index=X_train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_featured_f_regression.head(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Linear SVC(Support Vector Classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsvc_selector = SelectFromModel(LinearSVC(C=0.0001, penalty=\"l1\", dual=False))\n",
    "X_train_featured_lsvc = lsvc_selector.fit_transform(X_train, y_train)\n",
    "X_train_featured_lsvc = pd.DataFrame(X_train_featured_lsvc, columns=X_train.columns[lsvc_selector.get_support()], index=X_train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_featured_lsvc.head(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.B Zoraďte zistené atribúty v poradí podľa dôležitosti. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taktiež vieme pomocou `Mutual Information` urobiť ranking našich čŕt (features) podľa dôležitosti."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutual_info_scores = mutual_info_regression_selector.scores_\n",
    "\n",
    "feature_scores = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Mutual Information Score': mutual_info_scores\n",
    "})\n",
    "\n",
    "feature_scores = feature_scores.sort_values(by='Mutual Information Score', ascending=False).reset_index(drop=True)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.barplot(x='Mutual Information Score', y='Feature', data=feature_scores)\n",
    "plt.title(\"Features Ranked by Mutual Information Score\")\n",
    "plt.xlabel(\"Mutual Information Score\")\n",
    "plt.ylabel(\"Features\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.C Zdôvodnite Vaše voľby/rozhodnutie pre realizáciu (t.j. zdokumentovanie)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vyskúšali sme 3 metódy výberu čŕt (feature selection), a zisili sme, že nám dávajú totožné výsledky v zmysle nájdených \"silných\" čŕt (features).\n",
    "\n",
    "\n",
    "Medzi ne patrí:\n",
    "- c.dogalize\n",
    "- p.system\n",
    "- p.android.gm\n",
    "- p.android.packageinstaller\n",
    "- p.browser.provider\n",
    "\n",
    "Tieto čŕty sú najinformatívnejšie pre predikovanie našej predikovanej premennej `mwra`.\n",
    "\n",
    "V našom pipeline sme sa rozhodli, že použijeme metódu \"Mutual Information\" (`mutual_info_regression`) pre výber čŕt.\n",
    "\n",
    "Metóda \"Mutual information\" meria závislosť medzi jednotlivými črtami a cieľovou (predikovanou) premennou bez toho, aby predpokladala konkrétny typ vzťahu medzi nimi (lineárny alebo nelineárny). Keďže sa jej výsledky aj zhodovali s ostatnými metódami, tak sme sa ju práve z tohto dôvodu rozhodli použiť v našom pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Replikovateľnosť predspracovania"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.A Upravte váš kód realizujúci predspracovanie trénovacej množiny tak, aby ho bolo možné bez ďalších úprav znovu použiť na predspracovanie testovacej množiny v kontexte strojového učenia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Zrekapitulovanie toho, čo sme urobili manuálne bez \"sklearn pipeline\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```py\n",
    "\n",
    "df_connections = pd.read_csv('112/connections.csv', delimiter=',')\n",
    "df_processes   = pd.read_csv('112/processes.csv', delimiter=',')\n",
    "\n",
    "merged_data = df_connections.merge(df_processes, on=['imei', 'ts'], how='inner')\n",
    "merged_data['ts'] = pd.to_numeric(pd.to_datetime(merged_data['ts'], errors='coerce'))\n",
    "merged_data = merged_data.drop_duplicates()\n",
    "merged_data = merged_data.drop(columns=['mwra_y'])\n",
    "merged_data = merged_data.rename(columns={\"mwra_x\": \"mwra\"})\n",
    "\n",
    "X = merged_data.drop(columns='mwra')\n",
    "y = merged_data['mwra']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_train_impute = imputer.fit_transform(X_train)\n",
    "X_train = pd.DataFrame(X_train_impute, columns=X_train.columns, index=X_train.index)\n",
    "\n",
    "X_train, y_train = handle_outliers(X_train, y_train)\n",
    "\n",
    "min_max_scaler = MinMaxScaler()\n",
    "X_train_normalized = min_max_scaler.fit_transform(X_train)\n",
    "X_train_normalized = pd.DataFrame(X_train_normalized, columns=X_train.columns, index=X_train.index)\n",
    "\n",
    "power_transformer = PowerTransformer(method='yeo-johnson')\n",
    "X_train_normalized_power = power_transformer.fit_transform(X_train_normalized)\n",
    "X_train_normalized_power = pd.DataFrame(X_train_normalized_power, columns=X_train_normalized.columns, index=X_train_normalized.index)\n",
    "\n",
    "X_train = X_train_normalized_power.copy()\n",
    "\n",
    "mutual_info_regression_selector = SelectKBest(mutual_info_regression, k=5)\n",
    "X_train_featured_mutual_info_regression = mutual_info_regression_selector.fit_transform(X_train, y_train)\n",
    "X_train_featured_mutual_info_regression = pd.DataFrame(X_train_featured_mutual_info_regression, columns=X_train.columns[mutual_info_regression_selector.get_support()], index=X_train.index)\n",
    "\n",
    "X_train = X_train_featured_mutual_info_regression.copy()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Vytvorenie pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vytvorenie vlastnej triedy na ošetrenie outlierov."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# co-engineered with ChatGPT\n",
    "class OutlierHandler(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, threshold=1.5, outlier_fraction=0.05):\n",
    "        self.threshold = threshold\n",
    "        self.outlier_fraction = outlier_fraction\n",
    "        self.imputer = SimpleImputer(strategy='median')\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.iqr = np.percentile(X, 75, axis=0) - np.percentile(X, 25, axis=0)\n",
    "        self.lower_bound = np.percentile(X, 25, axis=0) - self.threshold * self.iqr\n",
    "        self.upper_bound = np.percentile(X, 75, axis=0) + self.threshold * self.iqr\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        outliers_mask = np.any((X < self.lower_bound) | (X > self.upper_bound), axis=1)\n",
    "        num_outliers = np.sum(outliers_mask)\n",
    "        total_samples = X.shape[0]\n",
    "        outlier_fraction = num_outliers / total_samples\n",
    "        \n",
    "        if outlier_fraction < self.outlier_fraction:\n",
    "            return X[~outliers_mask]\n",
    "        else:\n",
    "            X_imputed = X.copy()\n",
    "            X_imputed[outliers_mask] = np.nan\n",
    "            return self.imputer.fit_transform(X_imputed)\n",
    "        # X_imputed = X.copy()\n",
    "        # X_imputed[outliers_mask] = np.nan\n",
    "        # return self.imputer.fit_transform(X_imputed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trieda `OutlierHandler` je akokeby vlastný transformer a vie transformovať vstupné dáta tak, že malé množstvo outlierov odstráni a veľké množstvo outlierov nahradí hraničnými hodnotami. Slúžia na to funkcie `fit` a `transform`.\n",
    "\n",
    "- `fit()` - zistuje či sú záznamy obsahujú outlierov\n",
    "- `transform()` - odstraňuje alebo nahradzuje outlierov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.B Využite možnosti sklearn.pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prevedenie celého nášho doterajšieho manuálneho postupu do \"sklearn pipeline\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_connections = pd.read_csv('112/connections.csv', delimiter=',')\n",
    "df_processes = pd.read_csv('112/processes.csv', delimiter=',')\n",
    "\n",
    "merged_data = df_connections.merge(df_processes, on=['imei', 'ts'], how='inner')\n",
    "merged_data['ts'] = pd.to_numeric(pd.to_datetime(merged_data['ts'], errors='coerce'))\n",
    "merged_data = merged_data.drop_duplicates()\n",
    "merged_data = merged_data.drop(columns=['mwra_y'])\n",
    "merged_data = merged_data.rename(columns={\"mwra_x\": \"mwra\"})\n",
    "\n",
    "X = merged_data.drop(columns='mwra')\n",
    "y = merged_data['mwra']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('outlier_handler', OutlierHandler(threshold=1.5, outlier_fraction=0.05)),\n",
    "    ('scaler', MinMaxScaler()),\n",
    "    ('power_transformer', PowerTransformer(method='yeo-johnson')),\n",
    "    ('feature_selection', SelectKBest(mutual_info_regression, k=5))],\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "preprocessor_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Náš pipeline funguje nasledovne:\n",
    "- `SimpleImputer` - nahradí chýbajúce hodnoty za priemer\n",
    "- `OutlierHandler` - odstráni alebo nahradí outlierov\n",
    "- `MinMaxScaler` - škáluje dáta na jednotný rozsah\n",
    "- `PowerTransformer` - pokúsi sa transoformovať dáta na normálnu distribúciu (resp. distribúcie blízkej normálnej distribúcii)\n",
    "- `SelectKBest` - vyberie najinformatívnejšie črty (features) pre predikciu predikovanej premennej (`mwra`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_train = preprocessor_pipeline.transform(X_train)\n",
    "preprocessed_train = pd.DataFrame(preprocessed_train, columns=X_train.columns[preprocessor_pipeline.named_steps['feature_selection'].get_support()], index=X_train.index)\n",
    "\n",
    "preprocessed_test = preprocessor_pipeline.transform(X_test)\n",
    "preprocessed_test = pd.DataFrame(preprocessed_test, columns=X_test.columns[preprocessor_pipeline.named_steps['feature_selection'].get_support()], index=X_test.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ukážka trénovacích a testovacích dát po prejdení cez pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uloženie preprocesovaných dát do `.csv` súborov."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(X_train))\n",
    "print(len(y_train))\n",
    "print(len(X_test))\n",
    "print(len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre_preprocess_train = X_train.copy()\n",
    "# pre_preprocess_train = pre_preprocess_train[['c.dogalize']]\n",
    "# pre_preprocess_train = pre_preprocess_train.drop(columns=['c.dogalize'])\n",
    "# pre_preprocess_train[\"mwra\"] = y_train\n",
    "# pre_preprocess_train.to_csv('pre_preprocess_train.csv')\n",
    "# pre_preprocess_test = X_test.copy()\n",
    "# pre_preprocess_test = pre_preprocess_test[['c.dogalize']]\n",
    "# pre_preprocess_test = pre_preprocess_test.drop(columns=['c.dogalize'])\n",
    "# pre_preprocess_test[\"mwra\"] = y_test\n",
    "# pre_preprocess_test.to_csv('pre_preprocess_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessed_train = preprocessed_train[['c.dogalize']]\n",
    "# preprocessed_train = preprocessed_train.drop(columns=['c.dogalize'])\n",
    "\n",
    "preprocessed_train[\"mwra\"] = y_train\n",
    "preprocessed_train.to_csv('preprocessed_train.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessed_test = preprocessed_test[['c.dogalize']]\n",
    "# preprocessed_test = preprocessed_test.drop(columns=['c.dogalize'])\n",
    "\n",
    "preprocessed_test[\"mwra\"] = y_test\n",
    "preprocessed_test.to_csv('preprocessed_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fáza 3 - Strojové učenie\n",
    "\n",
    "<font color='salmon'>\n",
    "    <b>Poznámka:</b>\n",
    "    Toto je iba začiatok práce na fáze 3.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor_pipeline),\n",
    "    ('classifier', DecisionTreeClassifier()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier_pipeline.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy: 0.8411371237458194\n",
    "\n",
    "Classification Report:\n",
    "               precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.84      0.71      0.77      1116\n",
    "         1.0       0.84      0.92      0.88      1874\n",
    "\n",
    "    accuracy                           0.84      2990\n",
    "   macro avg       0.84      0.81      0.82      2990\n",
    "weighted avg       0.84      0.84      0.84      2990\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zdroje"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fáza 1**\n",
    "\n",
    "Prednášky a cvičenia z predmetu IAU.\n",
    "\n",
    "[IAU Github repozitár](https://github.com/FIIT-IAU/IAU-course)\n",
    "\n",
    "[Scipy dokumentácia](https://docs.scipy.org/doc/scipy/reference/index.html)\n",
    "\n",
    "[Numpy dokumentácia](https://numpy.org/doc/)\n",
    "\n",
    "[Pandas dokumentácia](https://pandas.pydata.org/docs/)\n",
    "\n",
    "[Typical Analysis Procedure](https://work.thaslwanter.at/Stats/html/statsAnalysis.html)\n",
    "\n",
    "**Fáza 2**\n",
    "\n",
    "Predošlé zdroje plus:\n",
    "\n",
    "[Scikit-learn dokumentácia](https://scikit-learn.org/1.5/api/index.html)\n",
    "\n",
    "[Feature importance](https://machinelearningmastery.com/calculate-feature-importance-with-python/)\n",
    "\n",
    "[Scaling](https://machinelearningmastery.com/standardscaler-and-minmaxscaler-transforms-in-python/)\n",
    "\n",
    "[Transformations](https://machinelearningmastery.com/power-transforms-with-scikit-learn/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
